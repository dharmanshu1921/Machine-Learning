{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Census Data for Predicting whether the Yearly Income Exceeds 50K "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective: \n",
    "To predict whether income exceeds 50K/yr based on census data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: Adult Data Set\n",
    "\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable description:\n",
    "    \n",
    "age: continuous\n",
    "\n",
    "workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "\n",
    "fnlwgt: continuous.\n",
    "\n",
    "education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "\n",
    "education-num: continuous.\n",
    "\n",
    "marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "\n",
    "occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "\n",
    "relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "\n",
    "race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "\n",
    "sex: Female, Male.\n",
    "\n",
    "capital-gain: continuous.\n",
    "\n",
    "capital-loss: continuous.\n",
    "\n",
    "hours-per-week: continuous.\n",
    "\n",
    "native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n",
    "\n",
    "class: >50K, <=50K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas and Numpy libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For preprocessing the data\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To split the dataset into train and test datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To model the Gaussian Navie Bayes classifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate the accuracy score of the model\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_df = pd.read_csv('adult.data', header = None, delimiter=' *, *', engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset. Observe that this file has .data extention\n",
    "\n",
    "For importing the census data, we are using pandas read_csv() method. This method is a very simple and fast method for importing \n",
    "data.\n",
    "\n",
    "We are passing four parameters. The ‘adult.data’ parameter is the file name. The header parameter is for giving details to pandas\n",
    "that whether the first row of data consists of headers or not. In our dataset, there is no header. So, we are passing None.\n",
    "\n",
    "The delimiter parameter is for giving the information the delimiter that is separating the data. Here, we are using ‘ , ’ \n",
    "delimiter. This delimiter is to show delete the spaces before and after the data values. This is very helpful when there is \n",
    "inconsistency in spaces used with data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print columns in the adult data set\n",
    "adult_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding headers to the dataframe \n",
    "adult_df.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital_status', 'occupation', 'relationship',\n",
    "                    'race', 'sex', 'capital_gain', 'capital_loss', 'hours_per_week', 'native_country', 'income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of records(rows) in the dataframe\n",
    "len(adult_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test whether there is any null value in our dataset or not. We can do this using isnull() method.\n",
    "adult_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above output shows that there is no “null” value in our dataset.\n",
    "\n",
    "Let’s try to test whether any categorical attribute contains a “?” in it or not. \n",
    "\n",
    "At times there exists “?” or ” ” in place of missing values. \n",
    "Using the below code snippet we are going to test whether adult_df data frame consists of categorical variables with values as “?”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in ['workclass','education','marital_status','occupation','relationship','race','sex','native_country','income']:\n",
    "    print(value,\":\", sum(adult_df[value] == '?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the above code snippet shows that there are 1836 missing values in workclass attribute. 1843 missing values in \n",
    "occupation attribute and 583 values in native_country attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "For preprocessing, we are going to make a duplicate copy of our original dataframe.\n",
    "\n",
    "We are duplicating adult_df to adult_df_rev dataframe. \n",
    "\n",
    "Observe that we have used deep copy while copying. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Deep copy of adult_df\n",
    "adult_df_rev = adult_df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before doing missing values handling task, we need some summary statistics of our dataframe. For this, we can use describe() \n",
    "method. It can be used to generate various summary statistics, excluding NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_df_rev.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are passing an “include” parameter with value as “all”, this is used to specify that. \n",
    "\n",
    "We want summary statistics of all the attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_df_rev.describe(include= 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imputation \n",
    "\n",
    "Some of the categorical values have missing values i.e, “?”. \n",
    "\n",
    "We replace the “?” with the above describe methods top row’s value. \n",
    "\n",
    "For example, we replace the “?” values of workplace attribute with “Private” value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in ['workclass','education','marital_status','occupation','relationship','race','sex','native_country','income']:\n",
    "    #adult_df_rev[value].replace(['?'], [adult_df_rev.describe(include='all')[value][2]],inplace='True')\n",
    "    replaceValue = adult_df_rev.describe(include='all')[value][2]\n",
    "    adult_df_rev[value][adult_df_rev[value]=='?'] = replaceValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(adult_df.workclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integer Encoding to Categorical Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Naive Bayes, we need to convert all the data values in one format.\n",
    "\n",
    "We are going to encode all the labels with the value between 0 and n_classes-1. \n",
    "\n",
    "For implementing this, we are going to use LabelEncoder of scikit learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "workclass_cat = le.fit_transform(adult_df.workclass)\n",
    "education_cat = le.fit_transform(adult_df.education)\n",
    "marital_cat   = le.fit_transform(adult_df.marital_status)\n",
    "occupation_cat = le.fit_transform(adult_df.occupation)\n",
    "relationship_cat = le.fit_transform(adult_df.relationship)\n",
    "race_cat = le.fit_transform(adult_df.race)\n",
    "sex_cat = le.fit_transform(adult_df.sex)\n",
    "native_country_cat = le.fit_transform(adult_df.native_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(workclass_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create New Columns with Integer-Encoded Categories for Each Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and Initialize the encoded categorical columns\n",
    "\n",
    "adult_df_rev['workclass_cat'] = workclass_cat\n",
    "adult_df_rev['education_cat'] = education_cat\n",
    "adult_df_rev['marital_cat'] = marital_cat\n",
    "adult_df_rev['occupation_cat'] = occupation_cat\n",
    "adult_df_rev['relationship_cat'] = relationship_cat\n",
    "adult_df_rev['race_cat'] = race_cat\n",
    "adult_df_rev['sex_cat'] = sex_cat\n",
    "adult_df_rev['native_country_cat'] = native_country_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_df_rev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discard the Original Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the old/original categorical columns from dataframe\n",
    "dummy_fields = ['workclass','education','marital_status','occupation','relationship','race', 'sex', 'native_country']\n",
    "adult_df_rev = adult_df_rev.drop(dummy_fields, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reindex all the columns properly. We have passed the list of column names as a parameter and axis=1 for reindexing the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_df_rev = adult_df_rev.reindex_axis(['age', 'workclass_cat', 'fnlwgt', 'education_cat',\n",
    "                                    'education_num', 'marital_cat', 'occupation_cat',\n",
    "                                    'relationship_cat', 'race_cat', 'sex_cat', 'capital_gain',\n",
    "                                    'capital_loss', 'hours_per_week', 'native_country_cat', \n",
    "                                    'income'], axis= 1)\n",
    "adult_df_rev.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have created multiple categorical columns like “marital_cat”, “race_cat” etc. !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrange data into independent variables and dependent variables\n",
    "X = adult_df_rev.values[:,:14]  ## Features\n",
    "Y = adult_df_rev.values[:,14]  ## Target...14th column is the Target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "# Train data size: 70% of original data\n",
    "# Test data size: 30% of original data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.3, random_state = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Naive Bayes Model\n",
    "\n",
    "Implement Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the object\n",
    "clf = GaussianNB()\n",
    "\n",
    "# Train the model with Training data\n",
    "clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now **GaussianNB** classifier is built. \n",
    "\n",
    "The classifier is trained using training data. \n",
    "\n",
    "We can use **fit()** method for training it. \n",
    "\n",
    "After building a classifier, our model is ready to make predictions. \n",
    "\n",
    "We can use **predict()** method with test set features as its parameters.\n",
    "\n",
    "## Evaluate the Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Accuracy\n",
    "Accuracy of our Gaussian Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(Y_test, Y_pred, normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
